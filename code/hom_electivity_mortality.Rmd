---
title: "Data Analysis"
author: "Kaitlyn J. Tonra & Christopher D. Wells"
date: "1/11/2021"
output: html_document
---

This script is for calculating electivity and mortality for rubble and container level analyses. 

Setup chunk: Includes packages, plot style, and definitions for important variables 
```{r setup, include=FALSE}

knitr::opts_knit$set(root.dir = "../git/homomalla_settlement_choice")

library(boot) #load for bootstrapping
library(vegan) #load for PERMANOVA
library(bcaboot)

library(tidyverse)
library(grid)
library(gridExtra)
library(ggpubr)

rm(list =  ls())
graphics.off()

# Create a bootstrapping function
samplemedian <- function(x, d) {return(median(x[d]))} 

# Define styles for making plots later
electivity_plot <- list(
  ylim(-1,1),
  geom_hline(yintercept = 0, linetype = "dashed", color = "black", size = 0.5))

electivity_theme <- function(){
  theme(axis.title = element_text (size = 10),
        axis.text = element_text (size = 10, color = "black"),
        panel.background = element_blank (),
        panel.grid.major = element_blank (),
        panel.grid.minor = element_blank (),
        plot.background = element_blank (),
        axis.line = element_line(size = 0.5, linetype = "solid", color = "black"),
        axis.ticks = element_line(size = 0.5, linetype = "solid", color = "black"),
        legend.position = "none")}

# Setup for calculating electivities (define parameters)
bootstrap <- 10000 #number of bootstraps
permutations <- 99999 #number of permutations
rubble_types <- 3 #number of different rubble types in the experiment
substratum_types <- 4 #number of substratum types from coralnet
settlement_day <- 6 #day chosen for the settlement electivity calculations
mortality_start <- 12 #first day to fit mortality rate to
mortality_end <- 26 #last day to fit mortality rate to
```

Import the data and rename. These are pulling data that use the second method of area calculations. 
```{r import}

#number of corals on each substratum type each day (raw data)
settlement_counts <- read_csv("../data/counts_raw.csv",
                              col_types = cols(container = col_character())) 

#calculated area of each rubble (from data prep). Called rubble_area2 to correspond with method2
rubble_area <- read_csv("../code/rubble_area2.csv",
                        col_types = cols(container = col_character(),
                                         cca = col_double(),
                                         bare = col_double(),
                                         ram = col_double())) 

#calculated area of each substratum type in a container (from data prep). Called patch_type_area2 to correspond with method2. 
patch_type_area <- read_csv("../code/patch_type_area2.csv",
                            col_types = cols(container = col_double(),
                                             bare = col_double(),
                                             cca = col_double(),
                                             ram = col_double(),
                                             spon = col_double())) 
```

Isolate day 6 settlement counts so we can use it later for electivity calculation. This includes data for both rubble level and patch level analyses.
```{r isolate settlement day}

day6_settlement_counts <- settlement_counts %>%
  
#add up settlers on each substratum
  mutate(bare = bt + bs + bb,
         cca = ct + cs + cb,
         ram = rt + rs + rb,
         spon = ot + os + ob) %>% 
  
#isolate settlement day data  
  filter(day == settlement_day) %>% 

  #remove extra columns  
  select(-position:-ob) 


day6_settlement_counts
```

Arrange the data so it's in the right shape for calculating electivities. 
```{r}

rubble_electivity_df <- 
  
# Add a column to get total settlers in each container   
     mutate(day6_settlement, total = bare + cca + ram + spon) %>% 
  
# This just changes the class type so we can use it later
     group_by(container, rubble_type) %>% 
                  
# Arrange data organized by container and rubble type  
     summarize(total = sum(total)) %>% 
  
# Change the shape of the dataframe                 
     pivot_wider(names_from = rubble_type, values_from = total) %>% 
  
# Add the rubble_area dataframe so we can use it for electivities                
     merge(rubble_area, by = "container") 

rubble_electivity_df
                        
```


```{r Calculate electivity}
#this chunk calculates electivites...

# function to calculate electivities 
get_electivity <- function(counts, areas){
  
  densities <- counts / areas
  
  total_density <- sum(densities)
  
  proportions <- densities / total_density    #i.e. Chesson's alpha
  
  ntypes <- length(counts)
  
  electivities <- (proportions - 1 / ntypes) / (proportions + 1 / ntypes)
  
  return(electivities)
  
}



```
elec <- data.frame("cca", "bare", "ram")
for(i in 1:9){
  counts <- c(rubble_merge$cca.x[i], rubble_merge$bare.x[i], rubble_merge$ram.x[i])
  areas <- c(rubble_merge$cca.y[i], rubble_merge$bare.y[i], rubble_merge$ram.y[i])
  elec[i, ] <- get_electivity(counts, areas)
}

elec.rub <- elec %>%
  rename(cca = X.cca., bare = X.bare., ram = X.ram.) %>%
  pivot_longer(cca:ram, names_to = "rubbletype", values_to = "electivity") %>%
  filter(!is.na(electivity)) %>%
  mutate(electivity = as.numeric(electivity),
         rubbletype = as.factor(rubbletype))

elec.rub
```

```{r, fig.width = 3, fig.height = 3}
ggdensity(elec.rub$electivity)
ggqqplot(elec.rub$electivity)
shapiro.test(scale(elec.rub$electivity)) #not normal

kruskal.test(electivity ~ rubbletype, data = elec.rub) #kruskal-wallis
pairwise.wilcox.test(elec.rub$electivity, elec.rub$rubbletype, p.adjust.method = "BH") #pairwise comparisons

cca <- bcajack(elec.rub$electivity[elec.rub$rubbletype == "cca"], B = 10000, func = samplemedian, verbose = FALSE)
bar <- bcajack(elec.rub$electivity[elec.rub$rubbletype == "bare"], B = 10000, func = samplemedian, verbose = FALSE)
ram <- bcajack(elec.rub$electivity[elec.rub$rubbletype == "ram"], B = 10000, func = samplemedian, verbose = FALSE)

conf <- data.frame("rubbletype" = c("cca", "bare", "ram"),
                   "median" = c(cca$B.mean[2], bar$B.mean[2], ram$B.mean[2]),
                   "lwr" = c(cca$lims[1], bar$lims[1], ram$lims[1]),
                   "upr" = c(cca$lims[9], bar$lims[9], ram$lims[9]))

ggplot() +
  geom_errorbar(aes(x = rubbletype, ymin = lwr, ymax = upr), conf, width = 0.5) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(aes(x = rubbletype, y = median, fill = rubbletype), conf, shape = 21, color = "black", size = 3) +
  scale_x_discrete(labels = c("Bare", "CCA", "Ramicrusta")) +
  scale_y_continuous(limits = c(-1, 1)) +
  labs(x = "Rubble type", y = "Electivity index") +
  electivity_theme() #medians with 95% bias-corrected and accelerated bootstrap confidence intervals
```



```{r Calculate electivity (old)}
# # Calculate proportion of total settlers on each substratum
# rubble_merge_density <- mutate(rubble_merge, 
#                              density_bare = bare.x/bare.y,
#                              density_cca = cca.x/cca.y,
#                              density_ram = ram.x/ram.y)  
# 
# # Add Chesson's alphas
# rubble_alphas <- mutate(rubble_merge_density, bare_a = density_bare / (density_bare + density_cca + density_ram),
#                              cca_a = density_cca / (density_bare + density_cca + density_ram),
#                              ram_a = density_ram / (density_bare + density_cca + density_ram))
# rubble_alphas
# 
# # Calculate the electivities
# rubble_electivities <- mutate(rubble_alphas, bare_e = (bare_a - 1 / rubble_types) / (bare_a + 1 / rubble_types),
#                                              cca_e = (cca_a - 1 / rubble_types) / (cca_a + 1 / rubble_types),
#                                              ram_e = (ram_a - 1 / rubble_types) / (ram_a + 1 / rubble_types)) 
# 
# rubble_electivities
```


